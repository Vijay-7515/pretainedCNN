{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMlOZbHTZouXngoH15YQRF7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DDe1fPu3-PhZ","executionInfo":{"status":"ok","timestamp":1753876618070,"user_tz":-330,"elapsed":8676,"user":{"displayName":"Vijay","userId":"05485919541076902823"}},"outputId":"0750cf83-4ecf-44a8-dcbe-f4eefdd17df9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Requirement already satisfied: albumentations in /usr/local/lib/python3.11/dist-packages (2.0.8)\n","Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.11/dist-packages (from albumentations) (2.0.2)\n","Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from albumentations) (1.16.0)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from albumentations) (6.0.2)\n","Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.11/dist-packages (from albumentations) (2.11.7)\n","Requirement already satisfied: albucore==0.0.24 in /usr/local/lib/python3.11/dist-packages (from albumentations) (0.0.24)\n","Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.11/dist-packages (from albumentations) (4.12.0.88)\n","Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.24->albumentations) (3.12.5)\n","Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.24->albumentations) (6.5.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations) (2.33.2)\n","Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations) (4.14.1)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations) (0.4.1)\n","2.0.8\n"]}],"source":["# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Install dependencies\n","!pip install -U albumentations\n","\n","import os\n","import torch\n","import torch.nn as nn\n","import numpy as np\n","import torch.optim as optim\n","from torchvision import transforms, datasets, models\n","import albumentations as A; print(A.__version__)\n","from albumentations.pytorch import ToTensorV2\n","from torch.utils.data import DataLoader\n"]},{"cell_type":"code","source":["# Albumentations augmentations\n","train_aug = A.Compose([\n","    A.RandomRotate90(),\n","    A.HorizontalFlip(),\n","    A.Affine(translate_percent={\"x\":0.1, \"y\":0.1}, scale=(0.9, 1.1), rotate=(-30, 30)),\n","    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2),\n","    A.GaussNoise(var_limit=(10.0, 50.0)),\n","    A.Resize(224, 224),\n","    A.Normalize(),  # This line is essential!\n","    ToTensorV2()\n","])\n","\n","val_aug = A.Compose([\n","    A.Resize(224, 224),\n","    A.Normalize(),  # Add normalization here too\n","    ToTensorV2()\n","])\n","\n","\n","class ThermalDataset(torch.utils.data.Dataset):\n","    def __init__(self, root, transform):\n","        self.dataset = datasets.ImageFolder(root)\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.dataset)\n","\n","    def __getitem__(self, idx):\n","        img, label = self.dataset[idx]\n","        img = np.array(img)\n","        img = self.transform(image=img)['image']\n","        return img, label\n","\n","# DataLoaders\n","train_ds = ThermalDataset('/content/drive/MyDrive/DATASET/train', train_aug)\n","val_ds   = ThermalDataset('/content/drive/MyDrive/DATASET/val', val_aug)\n","test_ds  = ThermalDataset('/content/drive/MyDrive/DATASET/test', val_aug)\n","\n","train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=2)\n","val_loader   = DataLoader(val_ds, batch_size=32, shuffle=False, num_workers=2)\n","test_loader  = DataLoader(test_ds, batch_size=32, shuffle=False, num_workers=2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KLGFMkPMBwTO","executionInfo":{"status":"ok","timestamp":1753876621458,"user_tz":-330,"elapsed":310,"user":{"displayName":"Vijay","userId":"05485919541076902823"}},"outputId":"b65e9b7a-5b0f-4bb2-bfe6-29b058b3e0d3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-16-654509002.py:7: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n","  A.GaussNoise(var_limit=(10.0, 50.0)),\n"]}]},{"cell_type":"code","source":["# Load MobileNetV2 pretrained on ImageNet\n","model = models.mobilenet_v2(pretrained=True)\n","# Replace classifier\n","in_features = model.classifier[1].in_features\n","model.classifier = nn.Sequential(\n","    nn.Dropout(0.5),\n","    nn.Linear(in_features, 2)\n",")\n","model = model.to('cuda')"],"metadata":{"id":"VFpKn81aEcBi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=1e-3, momentum=0.9, weight_decay=1e-4)\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.1)\n","\n","def train_one_epoch():\n","    model.train()\n","    total_loss, correct = 0, 0\n","    for imgs, labels in train_loader:\n","        imgs, labels = imgs.cuda(), labels.cuda()\n","        optimizer.zero_grad()\n","        outputs = model(imgs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item() * imgs.size(0)\n","        correct += (outputs.argmax(1) == labels).sum().item()\n","    return total_loss/len(train_ds), correct/len(train_ds)\n","\n","def evaluate(loader):\n","    model.eval()\n","    loss, correct = 0, 0\n","    with torch.no_grad():\n","        for imgs, labels in loader:\n","            imgs, labels = imgs.cuda(), labels.cuda()\n","            outputs = model(imgs)\n","            loss += criterion(outputs, labels).item() * imgs.size(0)\n","            correct += (outputs.argmax(1) == labels).sum().item()\n","    return loss/len(loader.dataset), correct/len(loader.dataset)\n","\n","# Training loop\n","best_acc = 0\n","for epoch in range(1, 41):\n","    train_loss, train_acc = train_one_epoch()\n","    val_loss, val_acc = evaluate(val_loader)\n","    scheduler.step()\n","    print(f\"Epoch {epoch}: Train Acc {train_acc:.4f}, Val Acc {val_acc:.4f}\")\n","    if val_acc > best_acc:\n","        best_acc = val_acc\n","        torch.save(model.state_dict(), 'mobilenetv2_best.pth')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4p7RFsvKEgV8","executionInfo":{"status":"ok","timestamp":1753881878191,"user_tz":-330,"elapsed":5250274,"user":{"displayName":"Vijay","userId":"05485919541076902823"}},"outputId":"de9dcdcf-44ed-483a-adcd-5d4324df2cb2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1: Train Acc 0.8337, Val Acc 0.9169\n","Epoch 2: Train Acc 0.9216, Val Acc 0.9340\n","Epoch 3: Train Acc 0.9414, Val Acc 0.9652\n","Epoch 4: Train Acc 0.9544, Val Acc 0.9407\n","Epoch 5: Train Acc 0.9582, Val Acc 0.9676\n","Epoch 6: Train Acc 0.9624, Val Acc 0.9688\n","Epoch 7: Train Acc 0.9670, Val Acc 0.9413\n","Epoch 8: Train Acc 0.9690, Val Acc 0.9639\n","Epoch 9: Train Acc 0.9738, Val Acc 0.9707\n","Epoch 10: Train Acc 0.9755, Val Acc 0.9756\n","Epoch 11: Train Acc 0.9748, Val Acc 0.9590\n","Epoch 12: Train Acc 0.9825, Val Acc 0.9743\n","Epoch 13: Train Acc 0.9802, Val Acc 0.9780\n","Epoch 14: Train Acc 0.9844, Val Acc 0.9762\n","Epoch 15: Train Acc 0.9823, Val Acc 0.9762\n","Epoch 16: Train Acc 0.9857, Val Acc 0.9823\n","Epoch 17: Train Acc 0.9892, Val Acc 0.9811\n","Epoch 18: Train Acc 0.9912, Val Acc 0.9811\n","Epoch 19: Train Acc 0.9893, Val Acc 0.9817\n","Epoch 20: Train Acc 0.9902, Val Acc 0.9811\n","Epoch 21: Train Acc 0.9908, Val Acc 0.9804\n","Epoch 22: Train Acc 0.9924, Val Acc 0.9817\n","Epoch 23: Train Acc 0.9910, Val Acc 0.9811\n","Epoch 24: Train Acc 0.9884, Val Acc 0.9817\n","Epoch 25: Train Acc 0.9906, Val Acc 0.9811\n","Epoch 26: Train Acc 0.9900, Val Acc 0.9817\n","Epoch 27: Train Acc 0.9905, Val Acc 0.9817\n","Epoch 28: Train Acc 0.9909, Val Acc 0.9835\n","Epoch 29: Train Acc 0.9916, Val Acc 0.9798\n","Epoch 30: Train Acc 0.9915, Val Acc 0.9817\n","Epoch 31: Train Acc 0.9930, Val Acc 0.9817\n","Epoch 32: Train Acc 0.9916, Val Acc 0.9811\n","Epoch 33: Train Acc 0.9906, Val Acc 0.9817\n","Epoch 34: Train Acc 0.9914, Val Acc 0.9811\n","Epoch 35: Train Acc 0.9923, Val Acc 0.9798\n","Epoch 36: Train Acc 0.9902, Val Acc 0.9804\n","Epoch 37: Train Acc 0.9914, Val Acc 0.9804\n","Epoch 38: Train Acc 0.9915, Val Acc 0.9798\n","Epoch 39: Train Acc 0.9911, Val Acc 0.9811\n","Epoch 40: Train Acc 0.9927, Val Acc 0.9835\n"]}]},{"cell_type":"code","source":["model.load_state_dict(torch.load('mobilenetv2_best.pth'))\n","test_loss, test_acc = evaluate(test_loader)\n","print(f\"Test Accuracy: {test_acc:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fxtrCBfxq8z0","executionInfo":{"status":"ok","timestamp":1753884844194,"user_tz":-330,"elapsed":195443,"user":{"displayName":"Vijay","userId":"05485919541076902823"}},"outputId":"62654369-929b-429f-edf2-8fcf44404e4f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Accuracy: 0.9975\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import classification_report, confusion_matrix\n","import numpy as np\n","\n","model.eval()\n","all_preds = []\n","all_labels = []\n","with torch.no_grad():\n","    for imgs, labels in test_loader:\n","        imgs, labels = imgs.cuda(), labels.cuda()\n","        outputs = model(imgs)\n","        preds = outputs.argmax(1).cpu().numpy()\n","        all_preds.extend(preds)\n","        all_labels.extend(labels.cpu().numpy())\n","\n","# Confusion matrix\n","cm = confusion_matrix(all_labels, all_preds)\n","print(\"Confusion Matrix:\\n\", cm)\n","\n","# Classification report\n","target_names = ['Female', 'Male']\n","print(classification_report(all_labels, all_preds, target_names=target_names))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_j4LU91ezENe","executionInfo":{"status":"ok","timestamp":1753886788751,"user_tz":-330,"elapsed":13071,"user":{"displayName":"Vijay","userId":"05485919541076902823"}},"outputId":"7b0c91dc-e614-4574-b3a7-8f04b60f7ede"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Confusion Matrix:\n"," [[394   1]\n"," [  1 414]]\n","              precision    recall  f1-score   support\n","\n","      Female       1.00      1.00      1.00       395\n","        Male       1.00      1.00      1.00       415\n","\n","    accuracy                           1.00       810\n","   macro avg       1.00      1.00      1.00       810\n","weighted avg       1.00      1.00      1.00       810\n","\n"]}]}]}